# 2026-02-02 작업

## 1. 데이터셋 정리
- (datasource.tsv <- the original)
  - 
- `inputs/dataset_proper.tsv` (8,879건) - 중복/반복 구매 제외한 유니크 상품 데이터셋 생성

#### 2. 오차 분석 스크립트 작성 및 실행
| 스크립트 | 기능 |
|----------|------|
| `error_distribution.py` | 오차 구간별 분포 시각화 |
| `error_top_items.py` | 카테고리별 오차 TOP N 추출 |
| `duplicate_variability.py` | 동일 상품 실측 편차 분석 |
| `category_pattern_analysis.py` | 카테고리별 오차 패턴 분석 |
| `extract_error_samples.py` | 오차 상위 N개 이미지 추출 |

#### 3. 핵심 발견 사항

**과대추정 카테고리 (AI가 너무 크게 추정)**
- 보이그룹 인형/피규어: 41.7%가 +50% 이상 오차
- 방송/예능 인형/피규어: 34.8%
- 원인: 작은 피규어(65~200g)에 300~800g 고정값 적용

**과소추정 카테고리 (AI가 너무 작게 추정)**
- 이어폰팁: 96.0%가 -50% 이하 오차 (20g 고정 추정)
- 볼링가방: 88.7% (볼링공 포함 무게 미인식)
- 화장품(토너/에센스): ~80% (세트 상품을 단품으로 인식)

**문제점**: AI가 특정 값(20g, 30g, 100g, 300g, 800g)에 고정되는 경향

#### 4. 카테고리별 데이터셋 분리
- `inputs/categories/` 폴더에 오차가 큰 TOP 10 카테고리 TSV 파일 생성

#### 5. 프롬프트 v2 작성
- `prompts/weight-volume.v2.system.txt` - 오차 패턴을 반영한 개선 프롬프트

---

### 현재 진행 상태
```
[1. 데이터 수집] ✅ → [2. 오차 분석] ✅ → [3. 프롬프트 개선] ✅ → [4. 재추정] ← 여기 → [5. 비교 평가]
```

### 다음 할 일
1. 새 프롬프트(v2)로 샘플 재추정 실행
2. 기존 vs 신규 추정 결과 비교 평가
